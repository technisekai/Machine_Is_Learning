# -*- coding: utf-8 -*-
"""Submission.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d77IqdQas_t3GelxJzCBUBXVzMsShHJm

library
"""

import pandas as pd
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from keras.layers import Dense, LSTM

"""dataframe"""

df =  pd.read_csv('Avocado.csv')
df = df[['Date', 'AveragePrice']]
df.tail()

"""data preprocessing"""

date = df['Date'].values
price = df['AveragePrice'].values

sum_train = int(len(date)*0.8)
sum_valid = int(len(date)*0.2)

date_train = date[0:sum_train]
date_valid = date[sum_train:len(date)]
price_train = price[0:sum_train]
price_valid = price[sum_train:len(date)]

print("Training data: ", len(date_train), ',', len(price_train))
print("Validation data: ", len(date_valid), ',', len(price_valid))

def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
  series = tf.expand_dims(series, axis=-1)
  ds = tf.data.Dataset.from_tensor_slices(series)
  ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
  ds = ds.flat_map(lambda w: w.batch(window_size +1))
  ds = ds.shuffle(shuffle_buffer)
  ds = ds.map(lambda w: (w[:-1], w[1:]))
  return ds.batch(batch_size).prefetch(1)

"""model"""

train_set = windowed_dataset(price_train, window_size=60, batch_size=100, shuffle_buffer=1000)
valid_set = windowed_dataset(price_valid, window_size=60, batch_size=100, shuffle_buffer=1000)
model = tf.keras.models.Sequential([
                                    tf.keras.layers.LSTM(60, return_sequences=True),
                                    tf.keras.layers.LSTM(60),
                                    tf.keras.layers.Dense(8, activation="relu"),
                                    tf.keras.layers.Dropout(0.5), 
                                    tf.keras.layers.Dense(1),
])

"""optimizer and loss function"""

optimizer = tf.keras.optimizers.SGD(lr=0.1, momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=["mae"])

"""callbacks"""

class callback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    #Nilai mae sebenarnya 0.281 namun pada callback diturunkan
    if(logs.get('mae') is not None and logs.get('mae') <= 0.278 and logs.get('val_mae') <= 0.278): 
      self.model.stop_training = True

callbacks = callback()

"""training model"""

history = model.fit(train_set, epochs=100, callbacks=[callbacks],
                    validation_data=(valid_set), verbose=2)

"""mae plot"""

plt.plot(history.history['mae'])
plt.plot(history.history['val_mae'])
plt.title('Plot Mae')
plt.ylabel('mae')
plt.xlabel('epoch')
plt.legend(['train_set', 'valid_set'], loc='upper left')
plt.show()

"""loss plot"""

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Plot loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train_set', 'valid_set'], loc='upper left')
plt.show()